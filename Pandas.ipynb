{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab02\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬의 장점으로는 데이터 분석에 필요한 라이브러리가 풍부한 점을 들수 있습니다.\n",
    "이번 시간에는 파이썬 데이터 분석 도구로 유명한 numpy, pandas,matplotlib들에 대해 소개하고 사용해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# < Pandas>\n",
    "\n",
    "> 판다스(pandas)는 파이썬을 이용한 오픈 소스 데이터 분석 도구 입니다. 계산 과학 분야에서 사용하는 기본 패키지인 NumPy를 기반으로 만들어서 매우 빠르고, 복잡한 데이터 처리 작업을 SQL등의 쿼리를 다루는 것보다 간편하게 할 수 있습니다.\n",
    "\n",
    "### < Pandas의 특징 >\n",
    "> - 부동 소수점 데이터뿐만 아니라 빠진 데이터(NaN으로 표시)를 손쉽게 처리한다.\n",
    "> - DataFrame 및 상위 차원 개체에서 열을 삽입하고 삭제할 수 있다.\n",
    "> - 개체를 레이블 세트에 명시적으로 정렬하거나 사용자가 레이블을 무시하고 Series, DataFrame 등으로 데이터를 사용할 수 있다.\n",
    "> - 데이터를 집계하거나 변환하기 위해 데이터 세트를 분할할 수 있는 강력하고 유연한 그룹 기능이 있다.\n",
    "> - 파이썬이나 NumPy 데이터 구조의 비정형 인덱스 데이터를 DataFrame 객체로 쉽게 변환해서 사용할 수 있다.\n",
    "> - 날짜 범위 생성, 날짜 데이터 빈도 변환, 날짜 이동과 지연 등 시계열 관련 기능을 포함한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > 데이터 타입 만들기 \n",
    "\n",
    "Pandas만의 특이한 data structure\n",
    "- **Series** (1-dimensional)\n",
    "- **DataFrame** (2-dimensiona): R의 data frame과 거의 흡사하며 이를 다루는 함수 또한 R과 매우 유사함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Series\n",
    "- 1차원 배열\n",
    "- 자동으로 성분들이 0부터 시작하는 정수로 인덱싱됨. 이는 list와 tuple과 유사함\n",
    "- 인덱스를 자신이 원하는 형태로 바꿀 수 있다는 점에서 dictionary와 유사함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Series 데이터 타입 만들기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas와 NumPy를 불러옵니다.\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 우선 한번 해볼까요!\n",
    "\n",
    "# s 에 Series 타입을 정의합니다.\n",
    "s = pd.Series([\"m\",\"i\",\"k\",\"u\",3,9,39,3.939])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Series 타입 생성 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5] #리스트를 만든다.\n",
    "a_array = np.array(a) #array로 선언하기\n",
    "a_series = pd.Series(a) # Series로 선언하기\n",
    "\n",
    "print(a)\n",
    "print(a_array)\n",
    "print(a_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = pd.Series([1,2,3,4,5])\n",
    "print(a)\n",
    "# 1열은 index, 2열은 Series의 성분이 출력됨\n",
    "\n",
    "b = pd.Series([1,3,5,np.nan,6,8]) # NaN: Not a Number\n",
    "print(b)\n",
    "# Series에는 type이 다른 성분을 넣을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Series 타입 생성 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 임의의 문자열로 인덱스 설정하기\n",
    "\n",
    "#index 파라미터를 이용해 임의의 문자열로 인덱스를 설정합니다.\n",
    "s= pd.Series(\n",
    "    [\"m\",\"i\",\"k\",\"u\",3,9,39,3.939], index=[\"A\",\"B\",\"X\",\"y\",\"kim\",\"seon\",\"young\",\"ZSeries 타입 생성 1.\"]\n",
    ")\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬의 딕셔너리 형태와 비슷하다는 것을 확인할 수 있습니다.  \n",
    "Series 타입을 만들 때는 깊이가 1인 딕셔너리를 그대로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Series 타입 생성 3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_dict = {\n",
    "    'ana':200, 'bastion':300, 'dva':500,\n",
    "    'genji':200, 'hanjo':200, 'junkrat':200,\n",
    "    'lucio':200, 'macree':200, 'mei':250,\n",
    "    'mercy':200, 'pharah':200, 'reaper':250\n",
    "}\n",
    "\n",
    "#해당 딕셔너리를 Series 타입으로 변환합니다.\n",
    "heroes_series = pd.Series(heroes_dict)\n",
    "heroes_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = pd.Series([10000, 20000, 30000, 40000, 50000])\n",
    "# print(a)\n",
    "# print(a[0])\n",
    "# print(a[2])\n",
    "\n",
    "# Series의 인덱싱을 날짜로 변경\n",
    "dates = pd.date_range('20160801', periods = 5)\n",
    "a = pd.Series([10000, 20000, 30000, 40000, 50000], index = dates)\n",
    "print(a)\n",
    "print(a['2016-08-01'])\n",
    "print(a['2016-08-03'])\n",
    "print(a[0])\n",
    "print(a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WikiDocs [파이썬을 이용한 시스템 트레이딩(기초편)] 에서 가져온 예제\n",
    "mine = pd.Series([10,20,30], index=['naver','skt','kt'])\n",
    "wife = pd.Series([10,30,20], index=['kt','naver','skt'])\n",
    "\n",
    "print(\"  내 주식\")\n",
    "print(mine)\n",
    "print('\\n')\n",
    "print(\" 아내 주식\")\n",
    "print(wife)\n",
    "\n",
    "family = mine + wife\n",
    "print('\\n')\n",
    "print(\" 가족 주식\")\n",
    "print(family)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Frame\n",
    "- 2차원 자료구조로 행과 열이 있는 테이블데이터(Tabular Data)를 받아들입니다.\n",
    "- 한가지 방법으로 아래 예제와 같이 열(column)을 dict의 Key로, 행(row)을 dict의 Value로 한 Dictionary 데이터를 pd.DataFrame()을 사용하여 pandas의 Data Frame 자료구조로 변환할 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [DataFrame 데이터 타입 만들기]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">DataFrame 타입은 Series 타입을 연결한 것입니다.  \n",
    ">즉, 2차원 배열이 됩니다. Series 타입 각각은 한 행(row)이 되고, Series의 인덱스는 열(column)이 된다고 생각하면 이해하기에 쉽습니다.\n",
    ">  \n",
    ">DataFrame 타입을 딕셔너리를 기반으로 만드는 방법은 Series타입과 동일합니다. 하지만 딕셔너리의 키가 Series 타입의 인덱스가 되었듯 DataFrame 타입을 만들 때 딕셔너리의 키는 열이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "data = {\n",
    "    'year': [2016, 2017, 2018],\n",
    "    'GDP rate': [2.8, 3.1, 3.0],\n",
    "    'GDP': ['1.637M', '1.73M', '1.83M']\n",
    "}\n",
    " \n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# WikiDocs [파이썬을 이용한 시스템 트레이딩(기초편)] 에서 가져온 예제\n",
    "raw_data = {'col0': [1,2,3,4],\n",
    "           'col1': [10,20,30,40],\n",
    "           'col2': [100,200,300,400]}\n",
    "data = pd.DataFrame(raw_data)\n",
    "print(data)\n",
    "print(data['col1'])\n",
    "\n",
    "print(type(raw_data)) # 위에서 정의한 raw_data는 dictionary임을 확인\n",
    "print(type(data)) # DataFrame이라는 type임을 확인\n",
    "print(type(data['col1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ 'A' : 1., \n",
    "                    'B' : pd.Timestamp('20130102'),\n",
    "                    'C' : pd.Series(1,index=list(range(4)),dtype='float32'),\n",
    "                    'D' : np.array([3] * 4,dtype='int32'),\n",
    "                    'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),\n",
    "                    'F' : 'foo' })\n",
    "\n",
    "print(df)\n",
    "print(df.dtypes)\n",
    "print(df.head(2))\n",
    "print(df.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {'temperature': [29, 34, 36, 32, 30],\n",
    "       'humidity': ['mid', 'high', 'high', 'mid', 'low'],\n",
    "       'weather': ['cloudy', 'sunny', 'rainy', 'cloudy', 'sunny']}\n",
    "a = pd.DataFrame(data)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# index에 날짜를 넣기\n",
    "date = ['2016-08-01', '2016-08-02', '2016-08-03', '2016-08-04', '2016-08-05']\n",
    "# 변수의 순서를 정해주기\n",
    "features = ['temperature', 'humidity', 'weather']\n",
    "b = pd.DataFrame(data, columns = features, index = date)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >데이터 불러오고 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터는 대부분 어느 정도 정제가 끝나서 파일로 저장된 경우가 많습니다. 처음부터 수동으로 데이터를 만드는 경우는 거의 없습니다.  \n",
    "정제된 데이터 대부분은 보통 CSV파일, 엑셀 파일, 데이터베이스 파일의 형태 중 하나일 겁니다.  \n",
    "이번에는 Pandas의 read_csv함수를 통해 데이터를 불러들이는 작업을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datapath = join('data','wine.txt')\n",
    "labelpath = join('data','wine_attributes.txt')\n",
    "\n",
    "columns = list()\n",
    "with open(labelpath, 'r') as f:\n",
    "    columns = f.read().split('\\n')\n",
    "    \n",
    "data = pd.read_csv(datapath, names = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >여러 가지 형태로 데이터 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 앞부분 살펴보기\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 조건에 맞춰 데이터 선택해 가져오기 - Series**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas에서는 매우 손쉽게 데이터를 선택하는 방법을 제공합니다.  \n",
    "  \n",
    "Pandas의 Series 타입에서 특정 데이터를 선택해 가져올 때는 리스트에서 데이터를 선택하는 방식과 똑같이 데이터를 선택해 가져오면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Series에서 0번째 데이터를 가져옵니다.\n",
    "heroes_series[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 특정 인덱스의 데이터를 슬라이스(선택)해서 가져오는 방법은 다음과 같습니다.  \n",
    " 또한 특정 값(index)과 연관된 데이터를 가져올 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 3~6 사이의 값을 선택해 가져옵니다.\n",
    "# 위에서의 실행결과 값과 다르게 index-data 를 같이 표시합니다.\n",
    "\n",
    "heroes_series[3:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dva라는 인덱스를 갖는 데이터를 가져옵니다.\n",
    "heroes_series['dva']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 조건에 맞춰 데이터 선택해 가져오기 - DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame 타입이라면 열 이름으로 데이터를 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data에서 열 이름이 Class, Ash에 해당하는 데이터를 가져옵니다.\n",
    "data[[\"Class\",\"Ash\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DataFrame에서 특정 열을 가져오는 방법 1\n",
    "data.Alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DataFrame에서 특정 열을 가져오는 방법 2\n",
    "data['Alcohol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 불리언 인덱싱(Boolean Indexing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas에서 데이터를 가져올 때는 불리언 인덱싱(boolean indexing)이라는 방법을 사용합니다.  \n",
    "[ ] 안에 들어가는 조건을 기준으로 데이터 프레임 안의 각 열을 순회하며 검사하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data의 Class 열에서 2인 값을 가져옵니다.\n",
    "data[data.Class==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 경우에는 Class열의 값이 2인 값들을 찾아 돌려준 것입니다.  \n",
    "위의 코드에서 [ ]안에 들어가는 부분만 따로 실행시켜보면 동작 원리를 좀 더 명확하게 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.Class == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 행을 검사해서 True인지 False인지 판정한 후에 True에 해당하는 행 데이터를 돌려주는 것입니다. 이 방법은 Series타입에서도 동일하게 적용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_series[heroes_series >=250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**두 가지 조건을 결합해 불리언 인덱싱 실행하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Class 열 값이 1 이면서, Magnesium 이 100 이상인 데이터만 선택합니다.\n",
    "data[\n",
    "    (data.Class == 1) & (data.Magnesium >= 110)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**인덱스 기준에 따라 데이터 다루기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame 타입의 [ ] 안에는 Series 타입에 대한 조건이 들어가야 합니다. 하지만 예외로 슬라이스 만큼은 지원합니다. 이는 너무나 보편적인 데이터 선택 방법이기 때문입니다.  \n",
    "하지만 단 하나의 행만 선택하고 싶을 때가 있습니다. 그럴 때 사용하는 것이 iloc() 과 loc()입니다.\n",
    "이 두 함수는 비슷해 보이지만 약간의 차이가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 함수를 사용하기 전에 인덱스를 Pandas가 기본으로 주는 인덱스(0으로 시작)말고 다른 것으로 바꾸어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df = data\n",
    "#data_df에 id열을 추가합니다.\n",
    "data_df=data_df.join(pd.DataFrame({'id':range(1,len(data)+1)}))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인덱스를 id라는 열로 변경합니다.\n",
    "data_df.set_index('id',inplace=True)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아까와는 달리 인덱스는 우리가 만들었던 id열이 되었습니다. 그럼 loc()과 iloc()이 어떻게 다른지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id 값이 3인 행 값을 모두 선택해 가져옵니다.\n",
    "data_df.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인덱스가 3인 행 값을 모두 선택해 가져옵니다.\n",
    "data_df.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "둘의 차이가 보이시나요? loc()는 현재 인덱스의 값을 기준으로 데이터를 가져옵니다.  \n",
    "하지만 iloc()는 무조건 인덱스값의 기준 0부터 시작하도록 강제하여 id가 3일지라도 첫 인덱스값을 0으로 계산해서 3인 데이터를 가져옵니다.    \n",
    "\n",
    "이러한 두 함수의 차이를 알아두면 인덱스의 값이 0부터 시작하지 않는 데이터를 다룰 때 매우 유용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >데이터 병합하기 `Data join`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. merge()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 병합할 때 가장 일반적으로 사용하는 Pandas의 함수는 merge()입니다.  \n",
    "데이터 사이에서 특정 기준에 따라 데이터를 병합하는 함수입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Join](./image/join.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data join\n",
    "\n",
    "Pandas의 merge함수는 4가지 유형의 병합을 지원합니다.   \n",
    "\n",
    "- inner: 두 프레임 사이 key들의 교집합(intersection)을 사용합니다. (SQL: inner join)\n",
    "- outer: 두 프레임 사이 key들의 합집합(union)을 사용합니다. (SQL: full outer join)\n",
    "- left: 왼쪽 프레임의 키만을 사용합니다.  (SQL: left outer join)\n",
    "- right: 오른쪽 프레임의 키만을 사용합니다. (SQL: right outer join)\n",
    "\n",
    "merge()의 디폴트(default)는 inner join입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = pd.DataFrame({'color': ['green', 'yellow', 'red'], 'num':[1, 2, 3]})\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B = pd.DataFrame({'color': ['green', 'yellow', 'pink'], 'size':['S', 'M', 'L']})\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<`Inner join`>**  \n",
    "A와 B에 동시에 등장하는 포인트들을 조인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left=A, right=B, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.merge(A, B, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**< `Outer join` >**  \n",
    "A 또는 B에 모두 등장하는 포인트들을 조인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.merge(A, B, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**< `Left join` >**  \n",
    "A에 포함된 포인트들만 조인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(A, B, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**< `Right join` >**  \n",
    "B에 포함된 포인트들만 조인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(A, B, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    " 특정 열을 명시적 키로 삼고 싶다면 'on' 파라미터에 특정 열 이름을 작성해 호출하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = pd.DataFrame({\n",
    "    \"id\":[1,2,3,4,5],\n",
    "    \"left_val\":[\"a\",\"b\",\"c\",\"d\",\"e\"]\n",
    "})\n",
    "\n",
    "temp2 = pd.DataFrame({\n",
    "    \"id\":[3,4,5,6,7],\n",
    "    \"right_val\":[\"q\",\"w\",\"e\",\"r\",\"t\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(temp1,temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(temp1,temp2,on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양쪽 DataFrame 타입에서 서로 다른 열을 기준으로 하고 싶다면 left_on과 right_on 파라미터를 설정하면됩니다.\n",
    "\n",
    "pd.merge(temp1,temp2,left_on=\"left_val\",right_on=\"right_val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge()를 다룰 때는 주로 겹치는 열이 있는 DataFrame 타입을 서로 병합하는 상황을 살펴봤습니다.  \n",
    "때에 따라서는 완전히 동일한 열을 가진 DataFrame 타입을 병합하는 상황도 있을 것입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3 = pd.DataFrame({\n",
    "    \"uid\":[122,123,124,125,126],\n",
    "    \"value\":[\"abc\",\"qwe\",\"asd\",\"zxc\",\"rty\"]\n",
    "})\n",
    "temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp4 = pd.DataFrame({\n",
    "    \"uid\":[1020,1021,1022,1023,1024],\n",
    "    \"value\":[\"love\",\"yourself\",\"set\",\"your love\",\"Upon him!\"]\n",
    "})\n",
    "temp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 temp3과 temp4를 이어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([temp3,temp4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >데이터 분석하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame 타입을 그룹화하고 다양한 형태로 분석하는 방법을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 그룹화 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그룹화할 때는 DataFrame타입에 groupby()를 사용하면 됩니다.  \n",
    "SQL을 다뤄봤다면 친숙한 이름일 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 다룬 wine데이터를 가지고 그룹화를 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_class = data_df.groupby('Class')\n",
    "by_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "groupby() 함수의 실행결과를 보면 또 다른 DataFrame 타입 데이터가 생성되는 것이 아니라 DataFrameGroupBy클래스의 객체가 되는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count()로 특정 열 값이 있는 행 개수 구하기\n",
    "\n",
    "by_class.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "값이 비어 있던 열이 없었으므로 위와 같이 모든 행의 값이 같게 나왔습니다.  \n",
    "특정 열로 그룹화한 행 개수만을 알고 싶다면 size()를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_class.size().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size()함수와 동일하게 바로 사용할 수 있게끔 준비된 여러 함수들이 존재합니다.\n",
    "  \n",
    "- mean() : 그룹 각 열의 평균값을 구합니다.\n",
    "- median() : 그룹 각 열의 중간값을 구합니다.\n",
    "- sum() : 그룹 각 열의 합을 구합니다.\n",
    "- min() : 그룹 각 열의 최솟값을 구합니다.\n",
    "- max() : 그룹 각 열의 최댓값을 구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_class.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Color intensity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color intensity를 사분위 수에 따라 categorize 합니다.\n",
    "binInterval = [1,3.22,4.69,6.2,13]\n",
    "binLabels = [0,1,2,3]\n",
    "data_df['color'] = pd.cut(data_df['Color intensity'],bins= binInterval, labels=binLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 번에 여러 개의 인덱스로 그룹화할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 열로 먼저 그룹화하고 그 안에서 color 열을 한 번 더 그룹화합니다.\n",
    "multi_indexed = data_df.groupby(['Class','color'])\n",
    "\n",
    "# 앞 groupby로 그룹화된 데이터를 설명하는 내용을 출력합니다.\n",
    "# 각 그룹 안의 전체 정보(개수, 유일한 값의 개수, 최댓값을 가진 인덱스, 출현 빈도)를 보여줍니다.\n",
    "multi_indexed.Alcohol.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describe()함수는 여러가지 수치들을 계산해 한 번에 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_class.describe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_group()를 이용해서 특정 그룹의 데이터들만 DataFrame 타입 데이터로 가져올수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "by_class.get_group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 가공하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agg() 와 apply() 함수로 적절히 의도에 맞게 데이터를 가공하는 실습을 해보도록 하겠습니다.  \n",
    "  \n",
    "특정 열에 대해 여러 가지 연산을 하고 싶을 때는 agg()를 사용하면 됩니다. 파이썬 딕셔너리 타입을 파라미터로 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_class.agg({\n",
    "    \"Alcohol\":\n",
    "    # 적용시킬 함수를 리스트로 전달합니다.\n",
    "    [\n",
    "        #(\"<레이블이름>\",<적용할 함수>)\n",
    "        (\"합계\", np.sum),\n",
    "        # <적용할 함수>\n",
    "        np.mean,\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블 이름과 함수를 튜플로 묶어서 전달하거나 함수 이름만 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등급별 Alcohol 열의 중간값(median) 구하기\n",
    "by_class.agg(\n",
    "{\n",
    "    \"Alcohol\":\n",
    "    [\n",
    "        np.size, np.median\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 튜플로 열 이름을 지정해 전달하지 않고 그냥 함수로만 전달하면, 바로 함수 이름을 열 이름으로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등급별 Alcohol의 제곱 합 구하기\n",
    "\n",
    "def sum_of_square(s:pd.core.series.Series):\n",
    "    # 각 그룹의 해당 열 Series 타입 데이터로 전달받습니다.\n",
    "    return sum([i**2 for i in s])\n",
    "\n",
    "by_class.agg({\"Alcohol\":[sum_of_square]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 그룹의 값에 특정 연산을 실행하는 것에 대해 실습해 보았습니다. 하지만 여러 개의 열에 작업하려면 agg()만으로는 부족하다고 느낄 수 있습니다.  \n",
    "이때 사용 하는 것이 apply()입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등급별로 Alcohol의 최댓값과 최솟값의 차이 구하기\n",
    "def get_diff_alcohol(df:pd.core.frame.DataFrame):\n",
    "    #apply()로 전달하는 함수의 파라미터는 각 그룹의 DataFrame 타입 데이터입니다.\n",
    "    return df.Alcohol.max()-df.Alcohol.min()\n",
    "by_class.apply(get_diff_alcohol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 각 그룹 안에서 연산해서 결과를 만들 수 있습니다.  \n",
    "앞서 배운 merge()를 사용하여 원래의 데이터 프레임에 그룹의 계산결과를 덧붙이는 등 다양한 시도를 해볼수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- 개발자를 위한 파이썬 - 윤웅식, 한빛미디어\n",
    "- the CS231n Python tutorial by Justin Johnson\n",
    "- IBM knowledge center"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung",
   "language": "python",
   "name": "samsung"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
